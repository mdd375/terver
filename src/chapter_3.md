# Условные вероятности

## Условная вероятность

**Определение:** Пусть A - некоторое событие, имеющее ненулевую вероятность. Тогда вероятность события B, при условии что имеет событие A равна
\\[ P_A(B) = P(B|A) = \dfrac{P(AB)}{P(A)} \\]

Покажем, что условная вероятность отвечает условиям Колмогорова:

1. \\( P_A(\Omega) = \dfrac{P(A\Omega)}{P(A)} = \dfrac{P(A)}{P(A)} = 1 \\)
2. \\( P_A(B) = \dfrac{P(AB)}{P(A)} \ge 0 \\)
3. Счётная аддитивность: Пусть \\( \\{B_i\\}^\infty_{i=1} \\) - последовательность независимых событий. Покажем, что \\( P_A(\cup^\infty_{i=1}B_i) = \cup^\infty_{i=1}P_A(B_i) \\).
\\[
        P_A(\bigcup^\infty_{i=1}B_i) = \dfrac{P(A(\bigcup^\infty_{i=1}B_i))}{P(A)}
                                     = \dfrac{P(\bigcup^\infty_{i=1}AB_i)}{P(A)}
                                     = \bigcup^\infty_{i=1} \dfrac{P(AB_i)}{P(A)}
                                     = \bigcup^\infty_{i=1}P_A(B_i)
\\]

### Теорема (Умножение вероятности)

> \\[ P(AB) = P(A) \cdot P_A(B) = P(B) \cdot P_B(A) \\]

#### Доказательство

\\[ P_B(A) = \dfrac{P(AB)}{P(B)} \Rightarrow P(AB) = P(B) \cdot P_B(A) \\]
\\[ P_A(B) = \dfrac{P(AB)}{P(A)} \Rightarrow P(AB) = P(A) \cdot P_A(B) \\]


## Независимость событий

**Определение:** События A и B называются независимыми, если
\\[ P(AB) = P(A) \cdot P(B) \\]

Чтобы отличать одни вероятности от других: \\( P_A(B) \\) - *условная вероятность*, \\( P(B) \\) - *безусловная вероятность*.

### Критерий независимости 2-х событий

> Предполагая, что \\( P(A) \ne 0 \\), \\( P(B) \ne 0 \\) А и B независимы тогда и только тогда, когда \\( P_B(A) = P(A) \\), то есть условная вероятность совпадает с безусловной.

#### Доказательство

A и B - независимы, равносильно по определению \\( P(AB) = P(A) \cdot P(B) \\). Но по теореме о умножении вероятностей \\( P(AB) = P_B(A) \cdot P(B) \\). А это означает, что \\( P_B(A) = P(A) \\).

**Определение:** Множество событий \\( \\{ A_1, \ldots, A_n \\} \\) называются попарно независимыми, если \\( \forall i \ne j \\) \\( P(A_iA_j) = P(A_i) \cdot P(A_j) \\).

**Определение:** События называются независимыми в совокупности, если любого сочетания \\( I \subset \\{ 1, \ldots, n \\} \\) выполняется
\\[ P \left( \bigcap_{i \in I}A_i \right) = \bigcap_{i \in I} P(A_i) \\]

### Теорема (о независимости дополнений)

> Если A и B независимы, то попарно независимы следующие пары: \\( A \\) и \\( \bar{B} \\), \\( \bar{A} \\) и \\( B \\), \\( \bar{A} \\) и \\( \bar{B} \\).

#### Доказательство

Используем критерий независимости:

\\[ P(\bar{B}|\bar{A}) = \dfrac{P(\bar{A}\bar{B})}{P(\bar{A})}
                       = \dfrac{1 - P(A + B)}{1 - P(A)}  
                       = \dfrac{(1 - P(A) - P(B) + P(A)P(B))}{1 - P(A)} = \\]
\\[                    = \dfrac{(1 - P(A))(1 - P(B))}{1 - P(A)} 
                       = 1 - P(B)
                       = P(\bar{B}) \\]

Остальные два случая доказываются аналогично.

## Полная вероятность

**Определение:** Множество конечных или счётных событий \\( \\{ A_i \\}^\infty_{i=1} \\), где n - либо число, либо бесконечность, называется *полной группой событий*, если выполняются следующие условия:

1. Любые \\( A_i \\) и \\( A_j \\) - независимы
2. \\( \sum^n_{i=1} P(A_i) = 1 \\)

\\( A_i \\) называются гипотезами.

### Формула полной вероятности

> Пусть \\( \\{ A_i \\} \\) - полная группа событий. Событие B задана на том же вероятностном пространстве, что и \\( A_i \\). Тогда справедлива формула:
\\[ P(B) = \sum^n_{i=1} P(B|A_i) \cdot P(A_i) \\] 

#### Доказательство

\\( \Omega = \bigcup^n_{i=1} A_i \\) 

\\( 1 = P(\Omega) = P(\bigcup^n_{i=1}A_i)) \\)

\\( P(B) = P(B \cdot \Omega) = P(B \cdot \bigcup^n_{i=1}A_i))) = P(\bigcup^n_{i=1}(B \cdot A_i)) \\)

Так как B и A независимы, то по теореме об умножении вероятностей

\\( \sum^n_{i=1} P(B \cdot A_i) = \sum^n_{i=1} P(B|A_i) \cdot P(A_i) \\)

### Формула Байеса

> Пусть выполнены все предположения полной вероятности. Тогда для любого i:
\\[ P(A_i|B) = \dfrac{P(B|A_i) \cdot P(A_i)}{P(B)} \\]

#### Доказательство

Следует из формулы умножения вероятности, применённой к паре \\( A_i \\) и \\( B \\):
\\[ P(A_iB) = P(A_i) \cdot P(B|A_i) = P(B) \cdot P(A_i|B) \\]
\\[ P(A_i|B) = \dfrac{P(B|A_i) \cdot P(A_i)}{P(B)} \\]

*Замечание:* \\( P(A_i) \\) называют априорными гипотезами.